{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy2vecMvO6UdzSoDsrbfVh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BChun11/DATA3001/blob/main/DATA3001_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OfiY_EjdwzkP"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all the files into google colab environment\n",
        "!git clone https://github.com/nokuik/KDDI-IoT-2019.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gws3W173w63G",
        "outputId": "d48204ef-6475-4904-ffcf-d26edcc8984a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KDDI-IoT-2019'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 42 (delta 1), reused 9 (delta 1), pack-reused 33\u001b[K\n",
            "Receiving objects: 100% (42/42), 776.84 MiB | 21.78 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all '.tar.gz files in ipfix directory\n",
        "%cd KDDI-IoT-2019\n",
        "%cd ipfix\n",
        "!ls *.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iRKf9sGw8-9",
        "outputId": "409283cd-ba92-4d4c-bf0f-39d7f396b00f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KDDI-IoT-2019\n",
            "/content/KDDI-IoT-2019/ipfix\n",
            " amazon_echo_gen2.tar.gz\t\t        nature_remo.tar.gz\n",
            " au_network_camera.tar.gz\t\t        panasonic_doorphone.tar.gz\n",
            " au_wireless_adapter.tar.gz\t\t        philips_hue_bridge.tar.gz\n",
            " bitfinder_awair_breathe_easy.tar.gz\t       'planex_camera_one_shot!.tar.gz'\n",
            " candy_house_sesami_wi-fi_access_point.tar.gz   planex_smacam_outdoor.tar.gz\n",
            " irobot_roomba.tar.gz\t\t\t        planex_smacam_pantilt.tar.gz\n",
            " jvc_kenwood_cu-hb1.tar.gz\t\t        powerelectric_wi-fi_plug.tar.gz\n",
            " jvc_kenwood_hdtv_ip_camera.tar.gz\t        qrio_hub.tar.gz\n",
            " line_clova_wave.tar.gz\t\t\t        sony_network_camera.tar.gz\n",
            " link_japan_eremote.tar.gz\t\t        sony_smart_speaker.tar.gz\n",
            " mouse_computer_room_hub.tar.gz\t\t        xiaomi_mijia_led.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all tar.gz files and store them in a variable\n",
        "files = !ls -1 *.tar.gz\n",
        "\n",
        "# Extract each tar.gz file\n",
        "for file in files:\n",
        "    print(f\"Extract {file} \")\n",
        "    !tar -xzvf {file}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUANXsatw-ur",
        "outputId": "0324e696-b1d4-45bc-9380-16b8036a902a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract amazon_echo_gen2.tar.gz \n",
            "amazon_echo_gen2.json\n",
            "Extract au_network_camera.tar.gz \n",
            "au_network_camera.json\n",
            "Extract au_wireless_adapter.tar.gz \n",
            "au_wireless_adapter.json\n",
            "Extract bitfinder_awair_breathe_easy.tar.gz \n",
            "bitfinder_awair_breathe_easy.json\n",
            "Extract candy_house_sesami_wi-fi_access_point.tar.gz \n",
            "candy_house_sesami_wi-fi_access_point.json\n",
            "Extract irobot_roomba.tar.gz \n",
            "irobot_roomba.json\n",
            "Extract jvc_kenwood_cu-hb1.tar.gz \n",
            "jvc_kenwood_cu-hb1.json\n",
            "Extract jvc_kenwood_hdtv_ip_camera.tar.gz \n",
            "jvc_kenwood_hdtv_ip_camera.json\n",
            "Extract line_clova_wave.tar.gz \n",
            "line_clova_wave.json\n",
            "Extract link_japan_eremote.tar.gz \n",
            "link_japan_eremote.json\n",
            "Extract mouse_computer_room_hub.tar.gz \n",
            "mouse_computer_room_hub.json\n",
            "Extract nature_remo.tar.gz \n",
            "nature_remo.json\n",
            "Extract panasonic_doorphone.tar.gz \n",
            "panasonic_doorphone.json\n",
            "Extract philips_hue_bridge.tar.gz \n",
            "philips_hue_bridge.json\n",
            "Extract 'planex_camera_one_shot!.tar.gz' \n",
            "planex_camera_one_shot!.json\n",
            "Extract planex_smacam_outdoor.tar.gz \n",
            "planex_smacam_outdoor.json\n",
            "Extract planex_smacam_pantilt.tar.gz \n",
            "planex_smacam_pantilt.json\n",
            "Extract powerelectric_wi-fi_plug.tar.gz \n",
            "powerelectric_wi-fi_plug.json\n",
            "Extract qrio_hub.tar.gz \n",
            "qrio_hub.json\n",
            "Extract sony_network_camera.tar.gz \n",
            "sony_network_camera.json\n",
            "Extract sony_smart_speaker.tar.gz \n",
            "sony_smart_speaker.json\n",
            "Extract xiaomi_mijia_led.tar.gz \n",
            "xiaomi_mijia_led.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the current working directory\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "\n",
        "# List the contents of the current working directory\n",
        "print(\"Contents of Current Directory:\", os.listdir())\n",
        "\n",
        "!cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKhSw0rtxBHG",
        "outputId": "6b306aca-bcd5-4671-91a5-eca2d07b1561"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content/KDDI-IoT-2019/ipfix\n",
            "Contents of Current Directory: ['sony_smart_speaker.tar.gz', 'jvc_kenwood_cu-hb1.json', 'bitfinder_awair_breathe_easy.json', 'mouse_computer_room_hub.tar.gz', 'jvc_kenwood_hdtv_ip_camera.tar.gz', 'google_home_gen1.tar.gz00', 'au_network_camera.tar.gz', 'sony_network_camera.json', 'xiaomi_mijia_led.json', 'candy_house_sesami_wi-fi_access_point.tar.gz', 'planex_camera_one_shot!.json', 'link_japan_eremote.json', 'link_japan_eremote.tar.gz', 'au_wireless_adapter.json', 'planex_smacam_pantilt.tar.gz', 'sony_network_camera.tar.gz', 'planex_smacam_outdoor.json', 'jvc_kenwood_hdtv_ip_camera.json', 'philips_hue_bridge.json', 'jvc_kenwood_cu-hb1.tar.gz', 'sony_bravia.tar.gz01', 'planex_smacam_outdoor.tar.gz', 'qrio_hub.json', 'philips_hue_bridge.tar.gz', 'amazon_echo_gen2.json', 'candy_house_sesami_wi-fi_access_point.json', 'line_clova_wave.json', 'irobot_roomba.json', 'i-o_data_qwatch.tar.gz01', 'au_network_camera.json', 'line_clova_wave.tar.gz', 'nature_remo.tar.gz', 'sony_bravia.tar.gz02', 'panasonic_doorphone.json', 'mouse_computer_room_hub.json', 'nature_remo.json', 'au_wireless_adapter.tar.gz', 'qrio_hub.tar.gz', 'panasonic_doorphone.tar.gz', 'i-o_data_qwatch.tar.gz00', 'bitfinder_awair_breathe_easy.tar.gz', 'xiaomi_mijia_led.tar.gz', 'google_home_gen1.tar.gz01', 'planex_smacam_pantilt.json', 'planex_camera_one_shot!.tar.gz', 'sony_smart_speaker.json', 'sony_bravia.tar.gz00', 'powerelectric_wi-fi_plug.json', 'irobot_roomba.tar.gz', 'powerelectric_wi-fi_plug.tar.gz', 'amazon_echo_gen2.tar.gz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to generate distinct tables for each json file using a limited subset\n",
        "\n",
        "# Define the directory where the JSON files are located\n",
        "json_directory = '/content/KDDI-IoT-2019/ipfix'\n",
        "\n",
        "# Get the list of all JSON files in the directory\n",
        "json_files = [f for f in os.listdir(json_directory) if f.endswith('.json')]\n",
        "\n",
        "# Create distinct tables for each json file\n",
        "tables = {}\n",
        "for json_file in json_files:\n",
        "    # strip .json suffix from device names\n",
        "    device_name = json_file.split('.')[0]\n",
        "    # Construct the full path to the JSON file\n",
        "    json_path = os.path.join(json_directory, json_file)\n",
        "    # Read the JSON file into a DataFrame, normalize the 'flows' column, and get the first 1000 rows\n",
        "    df = pd.json_normalize(pd.read_json(json_path, lines=True, nrows=1000)['flows'])\n",
        "\n",
        "    # Label the DataFrame with the device name\n",
        "    df['Device'] = device_name\n",
        "    tables[device_name] = df\n",
        "\n",
        "# Concatenate all the Dataframes in the tables dictionary into a single Dataframe\n",
        "df = pd.concat(tables.values(), ignore_index=True)"
      ],
      "metadata": {
        "id": "yLR0ygqcxDjk"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discarding certain attributes\n",
        "The primary goal of training our models is to focus on attributes that provide valuable and distinguishable information about the data"
      ],
      "metadata": {
        "id": "Lmyg8wTLj0yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of columns to be dropped\n",
        "drop_columns = ['flowStartMilliseconds',\n",
        "                'flowEndMilliseconds',\n",
        "                'sourceMacAddress',\n",
        "                'destinationMacAddress'\n",
        "]\n",
        "\n",
        "# Drop the columns from the dataset\n",
        "df = df.drop(columns=drop_columns)"
      ],
      "metadata": {
        "id": "SXlgw24Yjz4S"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "# 1. Integer Encoding for IP Addresses\n",
        "def ip_to_int(ip_str):\n",
        "    # If IPv4 address\n",
        "    if '.' in ip_str:\n",
        "        return int(''.join(ip_str.split('.')))\n",
        "    # If IPv6 address\n",
        "    elif ':' in ip_str:\n",
        "        return int(hashlib.sha256(ip_str.encode('utf-8')).hexdigest(), 16) % 10**8\n",
        "\n",
        "df['sourceIPv4Address'] = df['sourceIPv4Address'].apply(ip_to_int)\n",
        "df['destinationIPv4Address'] = df['destinationIPv4Address'].apply(ip_to_int)\n",
        "\n",
        "# 2. Label Encoding for other categorical attributes\n",
        "label_encoders = {}\n",
        "for col in ['flowAttributes', 'initialTCPFlags', 'unionTCPFlags', 'reverseInitialTCPFlags', 'reverseUnionTCPFlags', 'reverseFlowAttributes', 'collectorName', 'flowEndReason', 'firstEightNonEmptyPacketDirections', 'Device']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# 3. Convert hex to int\n",
        "for col in ['tcpSequenceNumber', 'reverseTcpSequenceNumber', 'vlanId', 'ipClassOfService']:\n",
        "    df[col] = df[col].apply(lambda x: int(x, 16))\n"
      ],
      "metadata": {
        "id": "xilRYLfYnrfj"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzBeoEvKmTOY",
        "outputId": "8af40245-a418-40cf-8d59-45ee57b93c5e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22000 entries, 0 to 21999\n",
            "Data columns (total 51 columns):\n",
            " #   Column                                    Non-Null Count  Dtype  \n",
            "---  ------                                    --------------  -----  \n",
            " 0   flowDurationMilliseconds                  22000 non-null  float64\n",
            " 1   reverseFlowDeltaMilliseconds              22000 non-null  float64\n",
            " 2   protocolIdentifier                        22000 non-null  int64  \n",
            " 3   sourceIPv4Address                         22000 non-null  int64  \n",
            " 4   sourceTransportPort                       22000 non-null  int64  \n",
            " 5   packetTotalCount                          22000 non-null  int64  \n",
            " 6   octetTotalCount                           22000 non-null  int64  \n",
            " 7   flowAttributes                            22000 non-null  int64  \n",
            " 8   destinationIPv4Address                    22000 non-null  int64  \n",
            " 9   destinationTransportPort                  22000 non-null  int64  \n",
            " 10  reversePacketTotalCount                   22000 non-null  int64  \n",
            " 11  reverseOctetTotalCount                    22000 non-null  int64  \n",
            " 12  reverseFlowAttributes                     22000 non-null  int64  \n",
            " 13  initialTCPFlags                           22000 non-null  int64  \n",
            " 14  unionTCPFlags                             22000 non-null  int64  \n",
            " 15  reverseInitialTCPFlags                    22000 non-null  int64  \n",
            " 16  reverseUnionTCPFlags                      22000 non-null  int64  \n",
            " 17  tcpSequenceNumber                         22000 non-null  int64  \n",
            " 18  reverseTcpSequenceNumber                  22000 non-null  int64  \n",
            " 19  ingressInterface                          22000 non-null  int64  \n",
            " 20  egressInterface                           22000 non-null  int64  \n",
            " 21  vlanId                                    22000 non-null  int64  \n",
            " 22  silkAppLabel                              22000 non-null  int64  \n",
            " 23  ipClassOfService                          22000 non-null  int64  \n",
            " 24  flowEndReason                             22000 non-null  int64  \n",
            " 25  collectorName                             22000 non-null  int64  \n",
            " 26  observationDomainId                       22000 non-null  int64  \n",
            " 27  tcpUrgTotalCount                          21694 non-null  float64\n",
            " 28  smallPacketCount                          21694 non-null  float64\n",
            " 29  nonEmptyPacketCount                       21694 non-null  float64\n",
            " 30  dataByteCount                             21694 non-null  float64\n",
            " 31  averageInterarrivalTime                   21694 non-null  float64\n",
            " 32  firstNonEmptyPacketSize                   21694 non-null  float64\n",
            " 33  largePacketCount                          21694 non-null  float64\n",
            " 34  maxPacketSize                             21694 non-null  float64\n",
            " 35  firstEightNonEmptyPacketDirections        22000 non-null  int64  \n",
            " 36  standardDeviationPayloadLength            21694 non-null  float64\n",
            " 37  standardDeviationInterarrivalTime         21694 non-null  float64\n",
            " 38  bytesPerPacket                            21653 non-null  float64\n",
            " 39  reverseTcpUrgTotalCount                   5295 non-null   float64\n",
            " 40  reverseSmallPacketCount                   5295 non-null   float64\n",
            " 41  reverseNonEmptyPacketCount                5295 non-null   float64\n",
            " 42  reverseDataByteCount                      5295 non-null   float64\n",
            " 43  reverseAverageInterarrivalTime            5295 non-null   float64\n",
            " 44  reverseFirstNonEmptyPacketSize            5295 non-null   float64\n",
            " 45  reverseLargePacketCount                   5295 non-null   float64\n",
            " 46  reverseMaxPacketSize                      5295 non-null   float64\n",
            " 47  reverseStandardDeviationPayloadLength     5295 non-null   float64\n",
            " 48  reverseStandardDeviationInterarrivalTime  5295 non-null   float64\n",
            " 49  reverseBytesPerPacket                     5237 non-null   float64\n",
            " 50  Device                                    22000 non-null  int64  \n",
            "dtypes: float64(24), int64(27)\n",
            "memory usage: 8.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the Device column and flowStartMilliseconds as labels\n",
        "labels_df = df['Device'].copy()\n",
        "\n",
        "# Drop the Device column from the original DataFrame\n",
        "df = df.drop(columns=['Device'])\n",
        "\n",
        "X = df\n",
        "y = labels_df\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "TsnlViXo0YPe"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dealing with Missing Values in our Dataset"
      ],
      "metadata": {
        "id": "MJCXCFutx3DJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining function to measure quality of each method"
      ],
      "metadata": {
        "id": "BlzLQ-YrBOKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  This function trains a RandomForestRegressor on the given data and then\n",
        "  predicts on the test data. It computes the MAE (Mean Absolute Error) between\n",
        "  the predicted values and the true validation target values\n",
        "\"\"\"\n",
        "def mae_score(X_train, X_test, y_train, y_test):\n",
        "  rfr_model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "  rfr_model.fit(X_train, y_train)\n",
        "  pred = rfr_model.predict(X_test)\n",
        "\n",
        "  # Compute MAE between the predictions and true test value\n",
        "  return mean_absolute_error(y_test, pred)\n"
      ],
      "metadata": {
        "id": "9eQUFAY8BM6a"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 1: Dropping Columns with Missing Values"
      ],
      "metadata": {
        "id": "B4LLi6KEzqLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get columns with missing values\n",
        "missing_col = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
        "\n",
        "# Drop the columns in the training and test data\n",
        "drop_Xtrain = X_train.drop(missing_col, axis=1)\n",
        "drop_Xtest = X_test.drop(missing_col, axis=1)\n",
        "\n",
        "# Get the MAE for first approach\n",
        "print(\"Method 1 MAE: \")\n",
        "print(mae_score(drop_Xtrain, drop_Xtest, y_train, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz6ynG6LyAMS",
        "outputId": "82943712-ba6f-4e8c-9b78-1d858eda6a0c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method 1 MAE: \n",
            "2.47395303030303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 2: Using imputation techniques to fill in Missing Values"
      ],
      "metadata": {
        "id": "KYin0PhADmgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create impute object\n",
        "impute = SimpleImputer()\n",
        "\n",
        "# Apply imputer to data\n",
        "impute_Xtrain = impute.fit_transform(X_train)\n",
        "impute_Xtest = impute.transform(X_test)\n",
        "\n",
        "# Convert numpy arrays back to pandas dataframes\n",
        "impute_Xtrain = pd.DataFrame(impute_Xtrain, columns=X_train.columns)\n",
        "impute_Xtest = pd.DataFrame(impute_Xtest, columns=X_test.columns)\n",
        "\n",
        "# Get the MAE for second approach\n",
        "print(\"Method 2 MAE: \")\n",
        "print(mae_score(impute_Xtrain, impute_Xtest, y_train, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elt5l-aPDuoE",
        "outputId": "67400154-5eb4-4b42-dc76-9043ac1e6e79"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method 2 MAE: \n",
            "2.4451712121212124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 3: Extension to Imputation"
      ],
      "metadata": {
        "id": "hbqnA6AlLAcX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7P_oUAiLJHC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}