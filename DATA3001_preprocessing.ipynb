{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BChun11/DATA3001/blob/main/DATA3001_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OfiY_EjdwzkP"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import hashlib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, roc_auc_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all the files into google colab environment\n",
        "!git clone https://github.com/nokuik/KDDI-IoT-2019.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gws3W173w63G",
        "outputId": "5288356f-b85f-4d17-c041-426eb26cd397"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KDDI-IoT-2019'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 42 (delta 1), reused 9 (delta 1), pack-reused 33\u001b[K\n",
            "Receiving objects: 100% (42/42), 776.84 MiB | 24.21 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all '.tar.gz files in ipfix directory\n",
        "%cd KDDI-IoT-2019\n",
        "%cd ipfix\n",
        "!ls *.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iRKf9sGw8-9",
        "outputId": "93293954-b980-4f89-beb4-4817879ccccd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KDDI-IoT-2019\n",
            "/content/KDDI-IoT-2019/ipfix\n",
            " amazon_echo_gen2.tar.gz\t\t        nature_remo.tar.gz\n",
            " au_network_camera.tar.gz\t\t        panasonic_doorphone.tar.gz\n",
            " au_wireless_adapter.tar.gz\t\t        philips_hue_bridge.tar.gz\n",
            " bitfinder_awair_breathe_easy.tar.gz\t       'planex_camera_one_shot!.tar.gz'\n",
            " candy_house_sesami_wi-fi_access_point.tar.gz   planex_smacam_outdoor.tar.gz\n",
            " irobot_roomba.tar.gz\t\t\t        planex_smacam_pantilt.tar.gz\n",
            " jvc_kenwood_cu-hb1.tar.gz\t\t        powerelectric_wi-fi_plug.tar.gz\n",
            " jvc_kenwood_hdtv_ip_camera.tar.gz\t        qrio_hub.tar.gz\n",
            " line_clova_wave.tar.gz\t\t\t        sony_network_camera.tar.gz\n",
            " link_japan_eremote.tar.gz\t\t        sony_smart_speaker.tar.gz\n",
            " mouse_computer_room_hub.tar.gz\t\t        xiaomi_mijia_led.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all tar.gz files and store them in a variable\n",
        "files = !ls -1 *.tar.gz\n",
        "\n",
        "# Extract each tar.gz file\n",
        "for file in files:\n",
        "    print(f\"Extract {file} \")\n",
        "    !tar -xzvf {file}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUANXsatw-ur",
        "outputId": "2c998986-4aff-490a-9eb1-165816fb143b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract amazon_echo_gen2.tar.gz \n",
            "amazon_echo_gen2.json\n",
            "Extract au_network_camera.tar.gz \n",
            "au_network_camera.json\n",
            "Extract au_wireless_adapter.tar.gz \n",
            "au_wireless_adapter.json\n",
            "Extract bitfinder_awair_breathe_easy.tar.gz \n",
            "bitfinder_awair_breathe_easy.json\n",
            "Extract candy_house_sesami_wi-fi_access_point.tar.gz \n",
            "candy_house_sesami_wi-fi_access_point.json\n",
            "Extract irobot_roomba.tar.gz \n",
            "irobot_roomba.json\n",
            "Extract jvc_kenwood_cu-hb1.tar.gz \n",
            "jvc_kenwood_cu-hb1.json\n",
            "Extract jvc_kenwood_hdtv_ip_camera.tar.gz \n",
            "jvc_kenwood_hdtv_ip_camera.json\n",
            "Extract line_clova_wave.tar.gz \n",
            "line_clova_wave.json\n",
            "Extract link_japan_eremote.tar.gz \n",
            "link_japan_eremote.json\n",
            "Extract mouse_computer_room_hub.tar.gz \n",
            "mouse_computer_room_hub.json\n",
            "Extract nature_remo.tar.gz \n",
            "nature_remo.json\n",
            "Extract panasonic_doorphone.tar.gz \n",
            "panasonic_doorphone.json\n",
            "Extract philips_hue_bridge.tar.gz \n",
            "philips_hue_bridge.json\n",
            "Extract 'planex_camera_one_shot!.tar.gz' \n",
            "planex_camera_one_shot!.json\n",
            "Extract planex_smacam_outdoor.tar.gz \n",
            "planex_smacam_outdoor.json\n",
            "Extract planex_smacam_pantilt.tar.gz \n",
            "planex_smacam_pantilt.json\n",
            "Extract powerelectric_wi-fi_plug.tar.gz \n",
            "powerelectric_wi-fi_plug.json\n",
            "Extract qrio_hub.tar.gz \n",
            "qrio_hub.json\n",
            "Extract sony_network_camera.tar.gz \n",
            "sony_network_camera.json\n",
            "Extract sony_smart_speaker.tar.gz \n",
            "sony_smart_speaker.json\n",
            "Extract xiaomi_mijia_led.tar.gz \n",
            "xiaomi_mijia_led.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the current working directory\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "\n",
        "# List the contents of the current working directory\n",
        "print(\"Contents of Current Directory:\", os.listdir())\n",
        "\n",
        "!cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKhSw0rtxBHG",
        "outputId": "79067eff-e108-4dcb-d626-f008ed4d5f4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content/KDDI-IoT-2019/ipfix\n",
            "Contents of Current Directory: ['irobot_roomba.tar.gz', 'nature_remo.tar.gz', 'jvc_kenwood_cu-hb1.tar.gz', 'candy_house_sesami_wi-fi_access_point.tar.gz', 'planex_smacam_outdoor.tar.gz', 'link_japan_eremote.tar.gz', 'sony_smart_speaker.tar.gz', 'jvc_kenwood_hdtv_ip_camera.tar.gz', 'google_home_gen1.tar.gz00', 'jvc_kenwood_cu-hb1.json', 'bitfinder_awair_breathe_easy.tar.gz', 'link_japan_eremote.json', 'xiaomi_mijia_led.tar.gz', 'planex_smacam_pantilt.json', 'irobot_roomba.json', 'mouse_computer_room_hub.json', 'line_clova_wave.json', 'xiaomi_mijia_led.json', 'powerelectric_wi-fi_plug.json', 'candy_house_sesami_wi-fi_access_point.json', 'planex_camera_one_shot!.tar.gz', 'sony_smart_speaker.json', 'amazon_echo_gen2.tar.gz', 'panasonic_doorphone.tar.gz', 'sony_bravia.tar.gz02', 'au_network_camera.tar.gz', 'i-o_data_qwatch.tar.gz01', 'sony_bravia.tar.gz00', 'i-o_data_qwatch.tar.gz00', 'planex_camera_one_shot!.json', 'qrio_hub.json', 'au_network_camera.json', 'sony_bravia.tar.gz01', 'sony_network_camera.json', 'bitfinder_awair_breathe_easy.json', 'philips_hue_bridge.tar.gz', 'planex_smacam_outdoor.json', 'amazon_echo_gen2.json', 'google_home_gen1.tar.gz01', 'planex_smacam_pantilt.tar.gz', 'mouse_computer_room_hub.tar.gz', 'panasonic_doorphone.json', 'au_wireless_adapter.tar.gz', 'philips_hue_bridge.json', 'sony_network_camera.tar.gz', 'line_clova_wave.tar.gz', 'powerelectric_wi-fi_plug.tar.gz', 'jvc_kenwood_hdtv_ip_camera.json', 'nature_remo.json', 'au_wireless_adapter.json', 'qrio_hub.tar.gz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to generate distinct tables for each json file using a limited subset\n",
        "\n",
        "# Define the directory where the JSON files are located\n",
        "json_directory = '/content/KDDI-IoT-2019/ipfix'\n",
        "\n",
        "# Get the list of all JSON files in the directory\n",
        "json_files = [f for f in os.listdir(json_directory) if f.endswith('.json')]\n",
        "\n",
        "# Create distinct tables for each json file\n",
        "tables = {}\n",
        "for json_file in json_files:\n",
        "    # strip .json suffix from device names\n",
        "    device_name = json_file.split('.')[0]\n",
        "    # Construct the full path to the JSON file\n",
        "    json_path = os.path.join(json_directory, json_file)\n",
        "    # Read the JSON file into a DataFrame, normalize the 'flows' column, and get the first 1000 rows\n",
        "    df = pd.json_normalize(pd.read_json(json_path, lines=True, nrows=1000)['flows'])\n",
        "\n",
        "    # Label the DataFrame with the device name\n",
        "    df['Device'] = device_name\n",
        "    tables[device_name] = df\n",
        "\n",
        "# Concatenate all the Dataframes in the tables dictionary into a single Dataframe\n",
        "df = pd.concat(tables.values(), ignore_index=True)"
      ],
      "metadata": {
        "id": "yLR0ygqcxDjk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discarding certain attributes\n",
        "The primary goal of training our models is to focus on attributes that provide valuable and distinguishable information about the data"
      ],
      "metadata": {
        "id": "Lmyg8wTLj0yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of columns to be dropped\n",
        "drop_columns = ['flowStartMilliseconds',\n",
        "                'flowEndMilliseconds',\n",
        "                'sourceMacAddress',\n",
        "                'destinationMacAddress'\n",
        "]\n",
        "\n",
        "# Drop the columns from the dataset\n",
        "df = df.drop(columns=drop_columns)"
      ],
      "metadata": {
        "id": "SXlgw24Yjz4S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Encode and transform categorical values since Decision Tree & Random Forest can't handle non-numeric\n",
        "  categorical data directly\n",
        "\"\"\"\n",
        "# Ordinal encoding for IP addresses\n",
        "def ip_to_ordinal(df, col_name):\n",
        "    # Generate unique codes for each unique IP address\n",
        "    codes, uniques = pd.factorize(df[col_name])\n",
        "    df[col_name] = codes\n",
        "    return df\n",
        "\n",
        "df = ip_to_ordinal(df, 'sourceIPv4Address')\n",
        "df = ip_to_ordinal(df, 'destinationIPv4Address')\n",
        "\n",
        "# Convert hex to int\n",
        "for col in ['tcpSequenceNumber', 'reverseTcpSequenceNumber', 'vlanId', 'ipClassOfService']:\n",
        "    df[col] = df[col].apply(lambda x: int(x, 16))\n",
        "\n",
        "# Label Encoding for the other categorical attributes\n",
        "label_encoders = {}\n",
        "for col in ['flowAttributes', 'initialTCPFlags', 'unionTCPFlags', 'reverseInitialTCPFlags', 'reverseUnionTCPFlags', 'reverseFlowAttributes', 'collectorName', 'flowEndReason', 'firstEightNonEmptyPacketDirections', 'Device']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n"
      ],
      "metadata": {
        "id": "xilRYLfYnrfj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the Device column as label\n",
        "labels_df = df['Device'].copy()\n",
        "\n",
        "# Drop the Device column from the original DataFrame\n",
        "df = df.drop(columns=['Device'])\n",
        "\n",
        "X = df\n",
        "y = labels_df\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "TsnlViXo0YPe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assessing the Performance of the Multi-Class Classifier\n",
        "- The print_score function is designmed to evaluate a multi-class classifier's performance using F1 score and ROC-AUC curve.\n",
        "- We're using the 'weighted' average for the F1 score and 'ovr' (One-vs-rest) approach for the multi-class ROC-AUC."
      ],
      "metadata": {
        "id": "bosAROnn7Ctx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate how well a classifier model is performing on the training data\n",
        "def print_score(cls, X_train, y_train, X_test, y_test, train=True):\n",
        "    if train:\n",
        "        X, y = X_train, y_train\n",
        "        data_type = \"Train\"\n",
        "    else:\n",
        "        X, y = X_test, y_test\n",
        "        data_type = \"Test\"\n",
        "\n",
        "    # The model 'cls' uses the features X to make predictions\n",
        "    pred_y = cls.predict(X)\n",
        "    prob = cls.predict_proba(X)\n",
        "\n",
        "    # Compute 'weighted' F1-Score\n",
        "    f1Score = f1_score(y, pred_y, average='weighted')\n",
        "    # Compute ROC-AUC for each class using 'One-vs-rest'\n",
        "    roc_auc = roc_auc_score(y, prob, average='weighted', multi_class='ovr')\n",
        "\n",
        "    # Print results\n",
        "    print(f\"=== {data_type} Data ===\")\n",
        "    print(f\"Weighted F1 Score = {f1Score:.4f}\\n\")\n",
        "    print(f'ROC-AUC score: {roc_auc:.4f}\\n')\n",
        "    print(\"_______________________________________________\")\n",
        "    print(classification_report(y, pred_y))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "aSWGblSI7Ddf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dealing with Missing Values in our Dataset"
      ],
      "metadata": {
        "id": "MJCXCFutx3DJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Decision Tree Classifier to evaluate which method for treating missing values is optimal"
      ],
      "metadata": {
        "id": "GyiFIVbJ5Bet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_rf_on_missing_data_method(X_train, X_test, y_train, y_test, method=\"drop\"):\n",
        "    # Handle missing values based on the specified method\n",
        "    if method == \"drop\":\n",
        "        # Drop columns with missing values\n",
        "        missing_col = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
        "        X_train = X_train.drop(missing_col, axis=1)\n",
        "        X_test = X_test.drop(missing_col, axis=1)\n",
        "\n",
        "    elif method == \"impute\":\n",
        "        # Using imputation to fill in the missing values\n",
        "        imputer = SimpleImputer()\n",
        "        X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
        "        X_test = pd.DataFrame(imputer.transform(X_test))\n",
        "\n",
        "    elif method == \"impute_indicator\":\n",
        "        # Make new columns indicating what will be imputed\n",
        "        for col in X_train.columns:\n",
        "            if X_train[col].isnull().any():\n",
        "                X_train[col + '_was_missing'] = X_train[col].isnull()\n",
        "                X_test[col + '_was_missing'] = X_test[col].isnull()\n",
        "        imputer = SimpleImputer()\n",
        "        X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
        "        X_test = pd.DataFrame(imputer.transform(X_test))\n",
        "\n",
        "    # Train and evaluate RandomForest classifier\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print_score(rf, X_train, y_train, X_test, y_test, train=True)\n",
        "    print_score(rf, X_train, y_train, X_test, y_test, train=False)\n",
        "\n",
        "# Evaluating the methods\n",
        "print(\"Method 1: Dropping columns with Missing values\")\n",
        "evaluate_rf_on_missing_data_method(X_train, X_test, y_train, y_test, method=\"drop\")\n",
        "\n",
        "print(\"\\nMethod 2: Imputation\")\n",
        "evaluate_rf_on_missing_data_method(X_train, X_test, y_train, y_test, method=\"impute\")\n",
        "\n",
        "print(\"\\nMethod 3: Imputation with Missing Indicators\")\n",
        "evaluate_rf_on_missing_data_method(X_train, X_test, y_train, y_test, method=\"impute_indicator\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15GQyYk-7MEN",
        "outputId": "0c4dcd22-d615-46ea-a67e-b1378e5e18be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method 1: Dropping columns with Missing values\n",
            "=== Train Data ===\n",
            "Weighted F1 Score = 1.0000\n",
            "\n",
            "ROC-AUC score: 1.0000\n",
            "\n",
            "_______________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       916\n",
            "           1       1.00      1.00      1.00       910\n",
            "           2       1.00      1.00      1.00       895\n",
            "           3       1.00      1.00      1.00       894\n",
            "           4       1.00      1.00      1.00       889\n",
            "           5       1.00      1.00      1.00       879\n",
            "           6       1.00      1.00      1.00       905\n",
            "           7       1.00      1.00      1.00       893\n",
            "           8       1.00      1.00      1.00       894\n",
            "           9       1.00      1.00      1.00       914\n",
            "          10       1.00      1.00      1.00       899\n",
            "          11       1.00      1.00      1.00       915\n",
            "          12       1.00      1.00      1.00       912\n",
            "          13       1.00      1.00      1.00       906\n",
            "          14       1.00      1.00      1.00       895\n",
            "          15       1.00      1.00      1.00       897\n",
            "          16       1.00      1.00      1.00       895\n",
            "          17       1.00      1.00      1.00       897\n",
            "          18       1.00      1.00      1.00       901\n",
            "          19       1.00      1.00      1.00       896\n",
            "          20       1.00      1.00      1.00       899\n",
            "          21       1.00      1.00      1.00       899\n",
            "\n",
            "    accuracy                           1.00     19800\n",
            "   macro avg       1.00      1.00      1.00     19800\n",
            "weighted avg       1.00      1.00      1.00     19800\n",
            "\n",
            "\n",
            "\n",
            "=== Test Data ===\n",
            "Weighted F1 Score = 0.9973\n",
            "\n",
            "ROC-AUC score: 0.9998\n",
            "\n",
            "_______________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        84\n",
            "           1       0.99      1.00      0.99        90\n",
            "           2       1.00      1.00      1.00       105\n",
            "           3       0.98      1.00      0.99       106\n",
            "           4       1.00      1.00      1.00       111\n",
            "           5       1.00      1.00      1.00       121\n",
            "           6       1.00      1.00      1.00        95\n",
            "           7       1.00      1.00      1.00       107\n",
            "           8       1.00      1.00      1.00       106\n",
            "           9       1.00      1.00      1.00        86\n",
            "          10       1.00      0.99      1.00       101\n",
            "          11       1.00      1.00      1.00        85\n",
            "          12       0.99      1.00      0.99        88\n",
            "          13       1.00      1.00      1.00        94\n",
            "          14       1.00      1.00      1.00       105\n",
            "          15       0.99      0.98      0.99       103\n",
            "          16       0.99      1.00      1.00       105\n",
            "          17       1.00      1.00      1.00       103\n",
            "          18       1.00      1.00      1.00        99\n",
            "          19       1.00      0.99      1.00       104\n",
            "          20       1.00      1.00      1.00       101\n",
            "          21       1.00      1.00      1.00       101\n",
            "\n",
            "    accuracy                           1.00      2200\n",
            "   macro avg       1.00      1.00      1.00      2200\n",
            "weighted avg       1.00      1.00      1.00      2200\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Method 2: Imputation\n",
            "=== Train Data ===\n",
            "Weighted F1 Score = 1.0000\n",
            "\n",
            "ROC-AUC score: 1.0000\n",
            "\n",
            "_______________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       916\n",
            "           1       1.00      1.00      1.00       910\n",
            "           2       1.00      1.00      1.00       895\n",
            "           3       1.00      1.00      1.00       894\n",
            "           4       1.00      1.00      1.00       889\n",
            "           5       1.00      1.00      1.00       879\n",
            "           6       1.00      1.00      1.00       905\n",
            "           7       1.00      1.00      1.00       893\n",
            "           8       1.00      1.00      1.00       894\n",
            "           9       1.00      1.00      1.00       914\n",
            "          10       1.00      1.00      1.00       899\n",
            "          11       1.00      1.00      1.00       915\n",
            "          12       1.00      1.00      1.00       912\n",
            "          13       1.00      1.00      1.00       906\n",
            "          14       1.00      1.00      1.00       895\n",
            "          15       1.00      1.00      1.00       897\n",
            "          16       1.00      1.00      1.00       895\n",
            "          17       1.00      1.00      1.00       897\n",
            "          18       1.00      1.00      1.00       901\n",
            "          19       1.00      1.00      1.00       896\n",
            "          20       1.00      1.00      1.00       899\n",
            "          21       1.00      1.00      1.00       899\n",
            "\n",
            "    accuracy                           1.00     19800\n",
            "   macro avg       1.00      1.00      1.00     19800\n",
            "weighted avg       1.00      1.00      1.00     19800\n",
            "\n",
            "\n",
            "\n",
            "=== Test Data ===\n",
            "Weighted F1 Score = 0.9896\n",
            "\n",
            "ROC-AUC score: 1.0000\n",
            "\n",
            "_______________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96        84\n",
            "           1       0.99      0.99      0.99        90\n",
            "           2       1.00      1.00      1.00       105\n",
            "           3       0.97      0.99      0.98       106\n",
            "           4       1.00      1.00      1.00       111\n",
            "           5       0.99      1.00      1.00       121\n",
            "           6       1.00      1.00      1.00        95\n",
            "           7       1.00      1.00      1.00       107\n",
            "           8       1.00      1.00      1.00       106\n",
            "           9       1.00      1.00      1.00        86\n",
            "          10       1.00      0.99      1.00       101\n",
            "          11       1.00      1.00      1.00        85\n",
            "          12       0.99      0.98      0.98        88\n",
            "          13       0.99      0.99      0.99        94\n",
            "          14       1.00      1.00      1.00       105\n",
            "          15       0.94      0.99      0.97       103\n",
            "          16       0.99      0.99      0.99       105\n",
            "          17       1.00      1.00      1.00       103\n",
            "          18       0.96      0.97      0.96        99\n",
            "          19       0.98      0.97      0.98       104\n",
            "          20       0.98      0.97      0.98       101\n",
            "          21       1.00      0.99      1.00       101\n",
            "\n",
            "    accuracy                           0.99      2200\n",
            "   macro avg       0.99      0.99      0.99      2200\n",
            "weighted avg       0.99      0.99      0.99      2200\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Method 3: Imputation with Missing Indicators\n",
            "=== Train Data ===\n",
            "Weighted F1 Score = 1.0000\n",
            "\n",
            "ROC-AUC score: 1.0000\n",
            "\n",
            "_______________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       916\n",
            "           1       1.00      1.00      1.00       910\n",
            "           2       1.00      1.00      1.00       895\n",
            "           3       1.00      1.00      1.00       894\n",
            "           4       1.00      1.00      1.00       889\n",
            "           5       1.00      1.00      1.00       879\n",
            "           6       1.00      1.00      1.00       905\n",
            "           7       1.00      1.00      1.00       893\n",
            "           8       1.00      1.00      1.00       894\n",
            "           9       1.00      1.00      1.00       914\n",
            "          10       1.00      1.00      1.00       899\n",
            "          11       1.00      1.00      1.00       915\n",
            "          12       1.00      1.00      1.00       912\n",
            "          13       1.00      1.00      1.00       906\n",
            "          14       1.00      1.00      1.00       895\n",
            "          15       1.00      1.00      1.00       897\n",
            "          16       1.00      1.00      1.00       895\n",
            "          17       1.00      1.00      1.00       897\n",
            "          18       1.00      1.00      1.00       901\n",
            "          19       1.00      1.00      1.00       896\n",
            "          20       1.00      1.00      1.00       899\n",
            "          21       1.00      1.00      1.00       899\n",
            "\n",
            "    accuracy                           1.00     19800\n",
            "   macro avg       1.00      1.00      1.00     19800\n",
            "weighted avg       1.00      1.00      1.00     19800\n",
            "\n",
            "\n",
            "\n",
            "=== Test Data ===\n",
            "Weighted F1 Score = 0.9896\n",
            "\n",
            "ROC-AUC score: 1.0000\n",
            "\n",
            "_______________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96        84\n",
            "           1       0.99      0.99      0.99        90\n",
            "           2       1.00      1.00      1.00       105\n",
            "           3       0.97      0.99      0.98       106\n",
            "           4       1.00      1.00      1.00       111\n",
            "           5       0.99      1.00      1.00       121\n",
            "           6       1.00      1.00      1.00        95\n",
            "           7       1.00      1.00      1.00       107\n",
            "           8       1.00      1.00      1.00       106\n",
            "           9       1.00      1.00      1.00        86\n",
            "          10       1.00      0.99      1.00       101\n",
            "          11       1.00      1.00      1.00        85\n",
            "          12       0.99      0.98      0.98        88\n",
            "          13       0.99      0.99      0.99        94\n",
            "          14       1.00      1.00      1.00       105\n",
            "          15       0.94      0.99      0.97       103\n",
            "          16       0.99      0.99      0.99       105\n",
            "          17       1.00      1.00      1.00       103\n",
            "          18       0.96      0.97      0.96        99\n",
            "          19       0.98      0.97      0.98       104\n",
            "          20       0.98      0.97      0.98       101\n",
            "          21       1.00      0.99      1.00       101\n",
            "\n",
            "    accuracy                           0.99      2200\n",
            "   macro avg       0.99      0.99      0.99      2200\n",
            "weighted avg       0.99      0.99      0.99      2200\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the Data"
      ],
      "metadata": {
        "id": "XQUOZfRvplep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Section"
      ],
      "metadata": {
        "id": "XJtxtaXcpsu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xu8NDCosPQ7",
        "outputId": "202ea8a8-a497-4686-ec80-6ba038683535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['flowDurationMilliseconds', 'reverseFlowDeltaMilliseconds',\n",
              "       'protocolIdentifier', 'sourceIPv4Address', 'sourceTransportPort',\n",
              "       'packetTotalCount', 'octetTotalCount', 'flowAttributes',\n",
              "       'destinationIPv4Address', 'destinationTransportPort',\n",
              "       'reversePacketTotalCount', 'reverseOctetTotalCount',\n",
              "       'reverseFlowAttributes', 'initialTCPFlags', 'unionTCPFlags',\n",
              "       'reverseInitialTCPFlags', 'reverseUnionTCPFlags', 'tcpSequenceNumber',\n",
              "       'reverseTcpSequenceNumber', 'ingressInterface', 'egressInterface',\n",
              "       'vlanId', 'silkAppLabel', 'ipClassOfService', 'flowEndReason',\n",
              "       'collectorName', 'observationDomainId', 'tcpUrgTotalCount',\n",
              "       'smallPacketCount', 'nonEmptyPacketCount', 'dataByteCount',\n",
              "       'averageInterarrivalTime', 'firstNonEmptyPacketSize',\n",
              "       'largePacketCount', 'maxPacketSize',\n",
              "       'firstEightNonEmptyPacketDirections', 'standardDeviationPayloadLength',\n",
              "       'standardDeviationInterarrivalTime', 'bytesPerPacket',\n",
              "       'reverseTcpUrgTotalCount', 'reverseSmallPacketCount',\n",
              "       'reverseNonEmptyPacketCount', 'reverseDataByteCount',\n",
              "       'reverseAverageInterarrivalTime', 'reverseFirstNonEmptyPacketSize',\n",
              "       'reverseLargePacketCount', 'reverseMaxPacketSize',\n",
              "       'reverseStandardDeviationPayloadLength',\n",
              "       'reverseStandardDeviationInterarrivalTime', 'reverseBytesPerPacket'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['ipClassOfService']"
      ],
      "metadata": {
        "id": "w1uzrbnLsRci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}